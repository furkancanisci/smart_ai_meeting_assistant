import whisper
import torch
import os

class AudioService:
    def __init__(self):        
        self.device = "cpu" 
        
        # DEÄÄ°ÅÄ°KLÄ°K BURADA: 'small' yerine 'medium' yapÄ±yoruz.
        # Bu model TÃ¼rkÃ§eyi Ã§ok daha iyi anlar.
        self.model_size = "medium" 
        
        self.model = None

    def load_model(self):
        """Modeli hafÄ±zaya yÃ¼kler (Lazy Loading)"""
        if self.model is None:
            print(f"ğŸ”„ Whisper '{self.model_size}' modeli yÃ¼kleniyor... (Bu iÅŸlem ilk seferde vakit alÄ±r)")
            # GPU varsa kullan, yoksa CPU
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model = whisper.load_model(self.model_size, device=device)
            print("âœ… Model yÃ¼klendi!")

    def transcribe(self, file_path: str):
        """Sesi metne Ã§evirir"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Dosya bulunamadÄ±: {file_path}")

        # Modeli yÃ¼kle
        self.load_model()

        # Ã‡eviri iÅŸlemini baÅŸlat
        # fp16=False -> CPU hatalarÄ±nÄ± Ã¶nlemek iÃ§in (GPU yoksa)
        result = self.model.transcribe(file_path, fp16=False, language="tr")

        return result

# Singleton instance (Her seferinde yeni class yaratmayalÄ±m)
audio_service = AudioService()
