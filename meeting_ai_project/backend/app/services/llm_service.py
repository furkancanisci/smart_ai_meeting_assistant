import os
import json
from datetime import datetime
import locale
from groq import Groq
from dotenv import load_dotenv

load_dotenv()

class LLMService:
    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY")
        if not self.api_key:
            print("âš ï¸ GROQ API KEY Eksik! .env dosyasÄ±nÄ± kontrol edin.")
            
        self.client = Groq(api_key=self.api_key)
        # En gÃ¼ncel ve yetenekli model
        self.model_name = "llama-3.3-70b-versatile"

    def _extract_json(self, content: str):
        """
        Yapay zeka Ã§Ä±ktÄ±sÄ±nÄ±n iÃ§inden JSON kÄ±smÄ±nÄ± Ã§ekip alÄ±r.
        """
        try:
            # 1. Temizle (Markdown ve boÅŸluklar)
            content = content.replace("```json", "").replace("```", "").strip()
            
            # 2. Direkt parse etmeyi dene
            return json.loads(content)
        except json.JSONDecodeError:
            # 3. EÄŸer yapamazsa, { ... } arasÄ±nÄ± bulmaya Ã§alÄ±ÅŸ (CÄ±mbÄ±zlama)
            start = content.find('{')
            end = content.rfind('}')
            if start != -1 and end != -1:
                json_str = content[start : end + 1]
                try:
                    return json.loads(json_str)
                except:
                    pass
            return {}

    async def correct_transcript(self, text: str):
        """
        Whisper hatalarÄ±nÄ± dÃ¼zeltir.
        """
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "Sen bir editÃ¶rsÃ¼n. Sadece metindeki bariz ses hatalarÄ±nÄ± dÃ¼zelt. Yorum yapma."},
                    {"role": "user", "content": text}
                ],
                model=self.model_name, 
                temperature=0.1,
            )
            return chat_completion.choices[0].message.content.strip()
        except Exception:
            return text

    async def extract_action_items(self, transcript: str):
        """
        ToplantÄ± dÃ¶kÃ¼mÃ¼nden gÃ¶revleri Ã§Ä±karÄ±r (Tarih AlgÄ±lama Dahil).
        """
        # BugÃ¼nÃ¼n tarihini al
        try:
            locale.setlocale(locale.LC_TIME, "tr_TR.UTF-8")
        except:
            try:
                locale.setlocale(locale.LC_TIME, "Turkish_Turkey.1254")
            except:
                pass
            
        current_date = datetime.now().strftime("%Y-%m-%d (%A)")

        system_prompt = f"""
        You are an AI Task Manager. Extract action items from the transcript.
        
        CONTEXT:
        - Current Date: {current_date}
        - Calculate relative dates (e.g., "tomorrow", "next Friday") based on the Current Date.
        - If a specific time is mentioned (e.g. "akÅŸama"), assume 17:00.
        
        RULES:
        1. "Ahmet yapsÄ±n", "Ben yaparÄ±m", "LazÄ±m", "Gerekli" -> TASKS.
        2. Output MUST be a valid JSON object with a single key "tasks".
        3. Do NOT add any conversational text. Just JSON.
        
        JSON FORMAT:
        {{
          "tasks": [
            {{
              "description": "Task description in Turkish",
              "assignee": "Name (or 'Belirsiz')",
              "due_date": "YYYY-MM-DD HH:MM (ISO Format) or null",
              "confidence": 0.9
            }}
          ]
        }}
        """
        
        user_prompt = f"TRANSCRIPT:\n{transcript}"

        try:
            print(f"ğŸ¤– Groq GÃ¶rev Analizi BaÅŸladÄ±... (Ref: {current_date})")
            
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                model=self.model_name, 
                temperature=0.1,
                response_format={"type": "json_object"} 
            )

            content = chat_completion.choices[0].message.content.strip()
            data = self._extract_json(content)
            
            tasks = []
            if "tasks" in data: tasks = data["tasks"]
            elif "action_items" in data: tasks = data["action_items"]
            elif isinstance(data, list): tasks = data
            
            print(f"âœ… Bulunan GÃ¶rev SayÄ±sÄ±: {len(tasks)}")
            return tasks

        except Exception as e:
            print(f"âŒ Kritik Groq HatasÄ± (GÃ¶rev): {e}")
            return []

    async def analyze_sentiment(self, transcript: str):
        """
        ToplantÄ±nÄ±n genel duygu durumunu analiz eder.
        """
        prompt = """
        Analyze the sentiment of this meeting transcript.
        Output ONLY a JSON object.
        
        FORMAT:
        {
            "mood": "One word Turkish label (e.g., Gergin, NeÅŸeli, Resmi, Verimli, NÃ¶tr)", 
            "score": 8 
        }
        (Score 1-10: 1=Very Negative/Tension, 10=Very Positive/Productive)
        """
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": transcript[:15000]} 
                ],
                model=self.model_name,
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            return self._extract_json(chat_completion.choices[0].message.content)
        except Exception as e:
            print(f"âŒ Duygu Analizi HatasÄ±: {e}")
            return {"mood": "NÃ¶tr", "score": 5}

    async def generate_executive_summary(self, transcript: str):
        """
        4 Maddeli YÃ¶netici Ã–zeti Ã‡Ä±karÄ±r.
        """
        prompt = """
        You are an Executive Assistant. Summarize the meeting in Turkish.
        Output ONLY a JSON object.
        
        JSON FORMAT:
        {
          "discussions": ["KonuÅŸulan madde 1", "KonuÅŸulan madde 2"],
          "decisions": ["AlÄ±nan karar 1", "AlÄ±nan karar 2"],
          "action_plan": ["Kim ne yapacak (KÄ±sa Ã¶zet)"],
          "deadlines": ["Varsa kritik tarihler"]
        }
        """
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": transcript[:15000]}
                ],
                model=self.model_name,
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            return self._extract_json(chat_completion.choices[0].message.content)
        except Exception as e:
            print(f"âŒ Ã–zet HatasÄ±: {e}")
            return {}

    async def chat_with_context(self, context: str, user_query: str):
        """
        Global veya Yerel fark etmeksizin, verilen Context'e gÃ¶re soruyu cevaplar.
        """
        system_prompt = """
        Sen 'Smart', tÃ¼m toplantÄ±larÄ±n verisine hakim akÄ±llÄ± bir asistansÄ±n.
        
        GÃ–REVÄ°N:
        Sana verilen 'BULUNAN VERÄ°LER' kÄ±smÄ±nÄ± analiz ederek kullanÄ±cÄ±nÄ±n sorusunu cevapla.
        
        KURALLAR:
        1. Hangi toplantÄ±da ne konuÅŸulduÄŸunu net belirt (Ã–rn: "25 Ocak tarihli toplantÄ±da Ahmet ÅŸundan bahsetti...").
        2. EÄŸer sorunun cevabÄ± verilerde yoksa "KayÄ±tlarÄ±mda buna dair net bir bilgi bulamadÄ±m" de. Uydurma.
        3. CevabÄ±n profesyonel, toparlayÄ±cÄ± ve TÃ¼rkÃ§e olsun.
        """
        
        user_input = f"""
        BULUNAN VERÄ°LER (CONTEXT):
        {context}
        
        KULLANICI SORUSU:
        {user_query}
        """

        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                model=self.model_name,
                temperature=0.3, 
            )
            return chat_completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ Chat HatasÄ±: {e}")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu an baÄŸlantÄ± kuramÄ±yorum."

llm_service = LLMService()