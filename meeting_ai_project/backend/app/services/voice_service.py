import torch
import soundfile as sf # <-- Torchaudio yerine Soundfile
import os
import numpy as np

# SpeechBrain import kontrolÃ¼
try:
    from speechbrain.inference.speaker import EncoderClassifier
except ImportError:
    EncoderClassifier = None

class VoiceService:
    def __init__(self):
        print("ðŸ”„ Ses TanÄ±ma Modeli HazÄ±rlanÄ±yor...")
        self.classifier = None
        save_path = "tmp_models/embedding_model"
        
        if EncoderClassifier:
            try:
                self.classifier = EncoderClassifier.from_hparams(
                    source="speechbrain/spkrec-ecapa-voxceleb", 
                    savedir=save_path,
                    run_opts={"device": "cpu"}
                )
                print("âœ… Ses TanÄ±ma Modeli HazÄ±r!")
            except Exception as e:
                print(f"âŒ Model YÃ¼kleme HatasÄ±: {e}")
                self.classifier = None
        else:
            print("âš ï¸ SpeechBrain kÃ¼tÃ¼phanesi eksik.")

    def extract_embedding(self, file_path: str):
        """
        Ses dosyasÄ±ndan 192 boyutlu vektÃ¶r Ã§Ä±karÄ±r.
        Soundfile kullanarak okur (HatasÄ±z).
        """
        if self.classifier is None:
            return [0.0] * 192

        try:
            # 1. Sesi Soundfile ile YÃ¼kle (Torchaudio yerine)
            signal_np, fs = sf.read(file_path)
            
            # 2. Tensor'a Ã§evir
            signal = torch.from_numpy(signal_np).float()
            
            # 3. EÄŸer Stereo ise Mono yap, boyut ekle
            if len(signal.shape) > 1:
                signal = signal.mean(dim=1) # Stereo -> Mono
            if signal.dim() == 1:
                signal = signal.unsqueeze(0) # [Batch, Time] formatÄ± iÃ§in

            # 4. VektÃ¶rÃ¼ Ã‡Ä±kar
            embeddings = self.classifier.encode_batch(signal)
            
            # 5. Listeye Ã‡evir
            vector = embeddings[0, 0, :].detach().cpu().numpy().tolist()
            return vector
        except Exception as e:
            print(f"âŒ VektÃ¶r Ã‡Ä±karma HatasÄ±: {e}")
            return [0.0] * 192

    def identify_speaker(self, segment_embedding: list, known_profiles: list):
        if not known_profiles or segment_embedding == [0.0]*192:
            return "Misafir", 0.0

        best_match_name = "Misafir"
        best_score = 0.0
        threshold = 0.30 

        vec_a = np.array(segment_embedding)
        norm_a = np.linalg.norm(vec_a)
        
        if norm_a == 0: return "Misafir", 0.0

        for profile in known_profiles:
            vec_b = np.array(profile["embedding"])
            norm_b = np.linalg.norm(vec_b)
            
            if norm_b == 0: continue

            dot_product = np.dot(vec_a, vec_b)
            score = dot_product / (norm_a * norm_b)

            if score > best_score:
                best_score = score
                best_match_name = profile["name"]

        if best_score > threshold:
            return best_match_name, best_score
        else:
            return "Misafir", best_score

voice_service = VoiceService()